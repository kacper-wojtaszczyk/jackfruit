# Layer 1 ‚Äî Ingestion

Fetch raw data from external environmental APIs and store unchanged in the raw bucket.

## Status

| Component | Status |
|-----------|--------|
| CDS API client (async job pattern) | ‚úÖ Done |
| CLI with flags (`--date`, `--dataset`, `--run-id`) | ‚úÖ Done |
| MinIO storage integration | ‚úÖ Done |
| Structured logging (slog/JSON) | ‚úÖ Done |
| CAMS Europe Air Quality datasets | ‚úÖ Done |
| Containerization (Docker) | ‚úÖ Done |
| Dagster orchestration | üöß In progress |
| GloFAS dataset | ‚è≥ Next |
| Retry/rate limiting | ‚è≥ Planned |

## Responsibilities

- API authentication and key management
- Rate limiting and retry logic
- Scheduling fetch jobs (via Dagster subprocess)
- Writing raw responses to `jackfruit-raw` bucket
- Logging for observability

## Does NOT Do

- Schema normalization or unit conversion
- Quality checks beyond "did the request succeed?"
- Derived metrics
- Parsing or transformation ‚Äî just fetch and dump

## Technology

**Language:** Go

**Why Go:**
- Single static binary ‚Äî trivial deployment
- Native concurrency (goroutines) for parallel fetching
- Explicit error handling
- Full control over HTTP without SDK abstractions

## Storage Contract

**Output bucket:** `jackfruit-raw`

**Object key pattern:**
```
{source}/{dataset}/{YYYY-MM-DD}/{run_id}.{ext}
```

**Example:**
```
ads/cams-europe-air-quality-forecasts-analysis/2025-03-12/01890c24-905b-7122-b170-b60814e6ee06.grib
ads/cams-europe-air-quality-forecasts-forecast/2025-03-12/01890c24-905b-7122-b170-b60814e6ee06.grib
```

**Rules:**
- Multiple ingests on same date have distinct run_ids (no overwrites)
- Extension currently hardcoded to `.grib` (detection TBD)
- Date in path is **ingest date** (when we fetched), not event date
- Run ID is UUIDv7 passed from orchestration (Dagster)
- Multi-variable files stored as-is (ETL splits them later)
- Dataset name includes request variants (e.g., CAMS analysis vs forecast are separate datasets)

## CLI Usage

```bash
./ingestion \
  --dataset=cams-europe-air-quality-forecasts-analysis \
  --date=2025-03-12 \
  --run-id=01890c24-905b-7122-b170-b60814e6ee06
```

**Environment variables required:**
- `ADS_BASE_URL` ‚Äî CDS API base URL
- `ADS_API_KEY` ‚Äî CDS API key
- `MINIO_ENDPOINT` ‚Äî MinIO endpoint (e.g., `localhost:9000`)
- `MINIO_ACCESS_KEY` ‚Äî MinIO access key
- `MINIO_SECRET_KEY` ‚Äî MinIO secret key
- `MINIO_BUCKET` ‚Äî Target bucket name
- `MINIO_USE_SSL` ‚Äî `true` or `false`

## Docker Usage

The ingestion app is containerized and can be invoked via `docker-compose` or standalone Docker.

### Via docker-compose (recommended)

```bash
# Build the image
docker compose build ingestion

# Run a single ingestion job
docker compose run --rm ingestion \
  --dataset=cams-europe-air-quality-forecasts-analysis \
  --date=2025-03-12 \
  --run-id=01890c24-905b-7122-b170-b60814e6ee06
```

The `ingestion` service uses the `ingestion` profile, so it won't start automatically with `docker-compose up`. It's designed to be invoked on-demand (e.g., by Dagster).

**How it works:**
- `depends_on` ensures MinIO is healthy before ingestion runs
- Environment variables are read from `.env` file or shell
- Logs stream to stdout (JSON format)
- Exit codes: `0` = success, `1` = config error, `2` = application error

### Via standalone Docker

```bash
# Build
docker build -t jackfruit-ingestion:latest ./ingestion-go

# Run (must have MinIO running and network accessible)
docker run --rm \
  --network jackfruit_jackfruit \
  -e ADS_BASE_URL=$ADS_BASE_URL \
  -e ADS_API_KEY=$ADS_API_KEY \
  -e MINIO_ENDPOINT=minio:9000 \
  -e MINIO_ACCESS_KEY=$MINIO_ACCESS_KEY \
  -e MINIO_SECRET_KEY=$MINIO_SECRET_KEY \
  -e MINIO_BUCKET=jackfruit-raw \
  jackfruit-ingestion:latest \
  --dataset=cams-europe-air-quality-forecasts-analysis \
  --date=2025-03-12 \
  --run-id=01890c24-905b-7122-b170-b60814e6ee06
```

### Exit Codes

Dagster (or any orchestrator) can use exit codes to decide retry strategy:

| Code | Meaning | Retry? |
|------|---------|--------|
| `0` | Success | N/A |
| `1` | Config error (missing env vars, invalid flags) | No ‚Äî fix config first |
| `2` | Application error (network, API, storage) | Maybe ‚Äî depends on error type |

Future: split code `2` into retryable (transient network) vs non-retryable (invalid dataset) errors.

## Data Strategy

### Size-Based Ingestion Rule

| Dataset Size | Strategy |
|--------------|----------|
| Small/medium | Go ingestion ‚Üí MinIO |
| Large (multi-GB) | ETL reads directly from public S3 |

### Geographic Scope

- **POC:** Europe only (smaller downloads, faster iteration)
- **Future:** Global coverage

## Data Sources

### Go Ingestion Targets (no public S3)

| Source | Data Types | API | Status |
|--------|------------|-----|--------|
| **Copernicus CAMS** | PM2.5, PM10, O3, NO2, AQI | CDS API | ‚úÖ Done |
| **Copernicus GloFAS** | River discharge, floods | CDS API | ‚è≥ Next |
| **Copernicus CGLS** | NDVI, LAI, land cover | CDS API | ‚è≥ Planned |

### Public S3 (ETL reads directly)

| Source | Bucket | Data Types |
|--------|--------|------------|
| ERA5 | `s3://era5-pds` | Weather reanalysis |
| NOAA GFS | `s3://noaa-gfs-bdp-pds` | Forecasts |
| MODIS | `s3://modis-pds` | Vegetation imagery |
| Sentinel-5P | `s3://meeo-s5p` | Atmospheric chemistry |

## CDS API Pattern

The Copernicus Data Store API uses an async job pattern:

1. **Submit** request ‚Üí get job ID
2. **Poll** status until complete
3. **Download** result file
4. **Store** to MinIO

This pattern applies to CAMS, GloFAS, and CGLS.

---

## Future Refactoring Ideas

High-level improvements to revisit after MVP:

### CDS Client
- [ ] **Options pattern for client config** ‚Äî timeouts, poll intervals as functional options
- [ ] **Extension detection** ‚Äî derive `.nc` vs `.grib` from Content-Type or asset type
- [ ] **Retry middleware** ‚Äî exponential backoff with jitter for transient failures
- [ ] **Rate limiting** ‚Äî token bucket or leaky bucket per API
- [ ] **Richer error types** ‚Äî distinguish retryable vs permanent failures

### CLI / Main
- [ ] **Subcommands** ‚Äî `ingestion fetch`, `ingestion list-datasets`, etc.
- [ ] **Config file support** ‚Äî YAML/TOML as alternative to env vars
- [ ] **Dry-run mode** ‚Äî validate request without executing

### Architecture
- [ ] **Adapter registry** ‚Äî map dataset ‚Üí adapter dynamically
- [ ] **Parallel fetching** ‚Äî goroutines for multiple datasets/dates
- [ ] **Progress reporting** ‚Äî structured events for Dagster to parse

### Testing
- [ ] **Integration test with real MinIO** ‚Äî docker-compose test harness
- [ ] **Golden file tests** ‚Äî snapshot CDS request payloads

